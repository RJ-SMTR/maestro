version: "3.7"

services:
  # This service runs the gRPC server that loads and executes your pipelines, in both dagit
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by dagit.
  dagster_pipelines:
    build:
      context: .
      dockerfile: ./Dockerfile_pipelines
    container_name: dagster_pipelines
    ports:
      - "4000:4000"
    environment:
      DAGSTER_POSTGRES_USER: "${DAGSTER_POSTGRES_USER}"
      DAGSTER_POSTGRES_PASSWORD: "${DAGSTER_POSTGRES_PASSWORD}"
      DAGSTER_POSTGRES_HOST: "${DAGSTER_POSTGRES_HOST}"
      DAGSTER_POSTGRES_DB: "${DAGSTER_POSTGRES_DB}"
      DAGSTER_CURRENT_IMAGE: "${COMPOSE_PROJECT_NAME}_dagster_pipelines"
      MODE: "${MODE}"
      BRT_DISCORD_WEBHOOK: "${BRT_DISCORD_WEBHOOK}"
      SPPO_DISCORD_WEBHOOK: "${SPPO_DISCORD_WEBHOOK}"
      FTPS_HOST: "${FTPS_HOST}"
      FTPS_USERNAME: "${FTPS_USERNAME}"
      FTPS_PWD: "${FTPS_PWD}"
      BQ_PROJECT_NAME: "${BQ_PROJECT_NAME}"
      QUERIES_DISCORD_WEBHOOK: "${QUERIES_DISCORD_WEBHOOK}"
    networks:
      - dagster_network
    volumes:
      - /home/${USER}/.basedosdados_dagster:/root/.basedosdados
      - /home/${USER}/maestro/repositories:/opt/dagster/app/repositories
      - /home/${USER}/maestro/data:/opt/dagster/app/data
      - /home/${USER}/maestro/bases:/opt/dagster/app/bases
      - /home/${USER}/RDO_DATA:/opt/dagster/app/data/RDO_DATA
      - /home/${USER}/GTFS_DATA:/opt/dagster/app/data/GTFS_DATA
      - /home/${USER}/FTPS_DATA:/opt/dagster/app/data/FTPS_DATA


  # This service runs dagit, which loads the pipelines from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from dagit will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  dagster_dagit:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagster_dagit
    expose:
      - "3000"
    ports:
      - "3000:3000"
    environment:
      DAGSTER_POSTGRES_USER: "${DAGSTER_POSTGRES_USER}"
      DAGSTER_POSTGRES_PASSWORD: "${DAGSTER_POSTGRES_PASSWORD}"
      DAGSTER_POSTGRES_HOST: "${DAGSTER_POSTGRES_HOST}"
      DAGSTER_POSTGRES_DB: "${DAGSTER_POSTGRES_DB}"
      MODE: "${MODE}"
      BRT_DISCORD_WEBHOOK: "${BRT_DISCORD_WEBHOOK}"
      SPPO_DISCORD_WEBHOOK: "${SPPO_DISCORD_WEBHOOK}"
      FTPS_HOST: "${FTPS_HOST}"
      FTPS_USERNAME: "${FTPS_USERNAME}"
      FTPS_PWD: "${FTPS_PWD}"
      BQ_PROJECT_NAME: "${BQ_PROJECT_NAME}"
      QUERIES_DISCORD_WEBHOOK: "${QUERIES_DISCORD_WEBHOOK}"
    networks:
      - dagster_network
    depends_on:
      - dagster_pipelines

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemon
    environment:
      DAGSTER_POSTGRES_USER: "${DAGSTER_POSTGRES_USER}"
      DAGSTER_POSTGRES_PASSWORD: "${DAGSTER_POSTGRES_PASSWORD}"
      DAGSTER_POSTGRES_HOST: "${DAGSTER_POSTGRES_HOST}"
      DAGSTER_POSTGRES_DB: "${DAGSTER_POSTGRES_DB}"
      DAGSTER_POSTGRES_DB: "${DAGSTER_POSTGRES_DB}"
      MODE: "${MODE}"
      BRT_DISCORD_WEBHOOK: "${BRT_DISCORD_WEBHOOK}"
      SPPO_DISCORD_WEBHOOK: "${SPPO_DISCORD_WEBHOOK}"
      FTPS_HOST: "${FTPS_HOST}"
      FTPS_USERNAME: "${FTPS_USERNAME}"
      FTPS_PWD: "${FTPS_PWD}"
      BQ_PROJECT_NAME: "${BQ_PROJECT_NAME}"
      QUERIES_DISCORD_WEBHOOK: "${QUERIES_DISCORD_WEBHOOK}"
    volumes: # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - dagster_network
    depends_on:
      - dagster_pipelines
    restart: always

  # This serves a Redis (https://redis.io/) server, which is used by pipelines
  # in order to tell the watchdog they're healthy.
  redis:
    image: redis:6
    restart: unless-stopped
    container_name: redis
    ports:
      - 6379:6379
    networks:
      - dagster_network

  # This serves the watchdog service itself. It checks Redis keys and restart
  # dagster containers if needed
  watchdog:
    build:
      context: ./watchdog
    restart: unless-stopped
    container_name: watchdog
    environment:
      PYTHONUNBUFFERED: 1
      WDT_DISCORD_WEBHOOK: "${WDT_DISCORD_WEBHOOK}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/${USER}/maestro/watchdog_config.yaml:/app/watchdog_config.yaml:ro
    networks:
      - dagster_network
    depends_on:
      - redis


networks:
  dagster_network:
    driver: bridge
    name: dagster_network
